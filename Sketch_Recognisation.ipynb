{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketch_Recognisation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yncf4_p5vbRO",
        "outputId": "32004863-fd40-4431-8b27-49976dd010ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPTPLLLuyhn2",
        "outputId": "03ba9eda-39be-4c82-ee87-376581083196"
      },
      "source": [
        "#To extract the rar file\n",
        "\n",
        "!pip install RarFile\n",
        "\n",
        "from rarfile import RarFile\n",
        "\n",
        "with RarFile(\"/content/drive/MyDrive/sketchy_dataset/10Classes.rar\") as rf:\n",
        "    rf.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting RarFile\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl\n",
            "Installing collected packages: RarFile\n",
            "Successfully installed RarFile-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPGU-qgVEnF"
      },
      "source": [
        "# Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLjhSQ60zjuX"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A0tqGfvyx6h",
        "outputId": "05cb0094-e8ea-455e-e116-ecfb26b3f766"
      },
      "source": [
        "completeData = tf.keras.preprocessing.image_dataset_from_directory('/content/10Classes', \n",
        "                                                                    labels='inferred', \n",
        "                                                                    label_mode='categorical',\n",
        "                                                                    batch_size=32,\n",
        "                                                                    image_size=(224, 224), \n",
        "                                                                    seed=3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5672 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aXx7B52zrt9",
        "outputId": "f314958c-45b6-47ec-8a45-2050d23c6429"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "\n",
        "for td in completeData:\n",
        "  for tx in td[0]:\n",
        "    X.append(tx)\n",
        "  for ty in td[1]:\n",
        "    Y.append(ty)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5672, 224, 224, 3) (5672, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksqlU0y9cajz"
      },
      "source": [
        "# Extracting features from images using pretrained VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j053oJXb6Ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db88a59a-278b-4656-9747-a0cd56b75b57"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model\n",
        "\n",
        "model = VGG16()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "\n",
        "features = model.predict(X, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKLi54DacJFy",
        "outputId": "209a28cb-3771-4826-f661-bee7e0ba3800"
      },
      "source": [
        "features.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5672, 4096), (5672, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYEEl8NchVr"
      },
      "source": [
        "# Reducing Dimensionality of the Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8VgJUY2clR6"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=100, random_state=22)\n",
        "pca.fit(features)\n",
        "x = pca.transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRULh3lQcxey",
        "outputId": "ad2ec6ec-9b07-40a2-8679-1bc4def621fb"
      },
      "source": [
        "x.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5672, 100), (5672, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huZPlF-mW0aI"
      },
      "source": [
        "# Standarizing the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C_TmLsYW4nR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(x)\n",
        "x_std = sc.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3oRQE8HV0Kg"
      },
      "source": [
        "# Splitting Dataset into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLO09XqbrMz9",
        "outputId": "c68f98bd-14ad-4f30-f723-3a83ba0197a1"
      },
      "source": [
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(x_std, Y, shuffle=True, test_size=0.2, random_state = 3)\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4537, 100) (4537, 10) (1135, 100) (1135, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lBe0KZmMmjQ"
      },
      "source": [
        "# Using RandomForestClassifier over our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXchDq7tr7Rt",
        "outputId": "393a1d73-0066-45ca-f53d-0c5a00c36391"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 7)  \n",
        "  \n",
        "clf.fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=7,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycYhW6nz1g-",
        "outputId": "cfe099cf-7d57-42ec-eb29-5f7319b8a43e"
      },
      "source": [
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(test_x)\n",
        "  \n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.5568281938325991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPQ8avU6MqLX"
      },
      "source": [
        "# Using Naive Bayes over our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2PofZT9USXd",
        "outputId": "c39f77a9-3ab0-40dc-906a-970251bb6a0f"
      },
      "source": [
        "train_x.shape, train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4537, 100), (4537, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ePaEGNYJf6"
      },
      "source": [
        "labels = np.argmax(train_y, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SynG7k3wMstU"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9379T-FWoD6",
        "outputId": "1e9fb880-792b-4d35-dd74-35ae329462ab"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "scores = model_selection.cross_val_score(gnb, train_x, labels, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Mean Score\", scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Score 0.7954628464852421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p4ahJ5GWUGF"
      },
      "source": [
        "# Using SVM classifier over the given dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYSPZXpvWXzk",
        "outputId": "138733ef-63cc-4053-d5a2-bb4983fa4e29"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Training a SVM classifier using SVC class\n",
        "svm = SVC(kernel= 'rbf', random_state=1, C=0.1)\n",
        "svm.fit(train_x, labels)\n",
        " \n",
        "# Mode performance\n",
        "y_labels = np.argmax(test_y, axis=1)\n",
        "y_pred = svm.predict(test_x)\n",
        "print('Accuracy: %.3f' % accuracy_score(y_labels, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXlmPzXc_ss"
      },
      "source": [
        "# Now trying the models on custom images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqEtMXJkwlzk"
      },
      "source": [
        "import cv2 \n",
        "\n",
        "def read_image(file):\n",
        "  originalImage = cv2.imread(file)\n",
        "  img = cv2.resize(originalImage, (224,224), interpolation=cv2.INTER_AREA)\n",
        "  img = np.array([img])\n",
        "  print(img.shape)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXn0ZeprxV1o"
      },
      "source": [
        "def return_reduced_features(model_vgg, img):\n",
        "  feat = model_vgg.predict(img)\n",
        "  x = pca.transform(feat)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f461OU-8yNNL"
      },
      "source": [
        "def predict_model(model, x):\n",
        "  pred = model.predict(x)\n",
        "  return np.argmax(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VpOLHNngJ1u"
      },
      "source": [
        "def get_label(model, image_path, model_vgg):\n",
        "  img = read_image(image_path)\n",
        "  x = return_reduced_features(model_vgg, img)\n",
        "  pred = predict_model(model, x)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ENxl6DpZoa5"
      },
      "source": [
        "# Now let's use a Neural Network to do all of this but with more number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8neCsIKbA-L"
      },
      "source": [
        "with RarFile(\"/content/drive/MyDrive/sketchy_dataset/Small.rar\") as rf:\n",
        "    rf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjQpN30aezX",
        "outputId": "0847ae08-f23d-420e-d3ff-05d882229e5e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "bigDataset = tf.keras.preprocessing.image_dataset_from_directory('/content/Small', \n",
        "                                                                    labels='inferred', \n",
        "                                                                    label_mode='categorical',\n",
        "                                                                    batch_size=32,\n",
        "                                                                    image_size=(224, 224), \n",
        "                                                                    validation_split=0.5,   \n",
        "                                                                    subset='training',\n",
        "                                                                    seed=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13949 files belonging to 24 classes.\n",
            "Using 6975 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AsYqlkFa9_H",
        "outputId": "557a289d-547a-457e-f6d0-6baf168fafc7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "\n",
        "for td in bigDataset:\n",
        "  for tx in td[0]:\n",
        "    X.append(tx)\n",
        "  for ty in td[1]:\n",
        "    Y.append(ty)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6975, 224, 224, 3) (6975, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9q0vMurbN-7"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model\n",
        "\n",
        "model_vgg = VGG16()\n",
        "model_vgg = Model(inputs = model_vgg.inputs, outputs = model_vgg.layers[-2].output)\n",
        "\n",
        "features = model_vgg.predict(X, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVKuWwK6cvnZ",
        "outputId": "5837a958-dfda-4a02-9663-d084c3bd2edb"
      },
      "source": [
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(features, Y, shuffle=True, test_size=0.2, random_state = 3)\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5580, 4096) (5580, 24) (1395, 4096) (1395, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNVDSIX-baiZ",
        "outputId": "aa754337-5269-44e3-d944-fac4e145623b"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "\n",
        "# Creating a Simple Dense Network \n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=train_x.shape[1:]))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(24, activation='softmax')) \n",
        "# Train model\n",
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 4,788,888\n",
            "Trainable params: 4,788,888\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ghr-i1dAqH",
        "outputId": "1f0842b6-7fef-4a31-bccf-412bc8230cc3"
      },
      "source": [
        "model.fit(train_x, train_y, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 - 2s - loss: 2.2826 - top_k_categorical_accuracy: 0.6860 - val_loss: 1.3631 - val_top_k_categorical_accuracy: 0.8763\n",
            "Epoch 2/5\n",
            "20/20 - 0s - loss: 1.2762 - top_k_categorical_accuracy: 0.9054 - val_loss: 0.9891 - val_top_k_categorical_accuracy: 0.9301\n",
            "Epoch 3/5\n",
            "20/20 - 0s - loss: 0.9364 - top_k_categorical_accuracy: 0.9446 - val_loss: 0.8322 - val_top_k_categorical_accuracy: 0.9444\n",
            "Epoch 4/5\n",
            "20/20 - 0s - loss: 0.7897 - top_k_categorical_accuracy: 0.9600 - val_loss: 0.7675 - val_top_k_categorical_accuracy: 0.9534\n",
            "Epoch 5/5\n",
            "20/20 - 0s - loss: 0.6807 - top_k_categorical_accuracy: 0.9727 - val_loss: 0.7051 - val_top_k_categorical_accuracy: 0.9659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7eff012ee690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lY9-yxsdG07",
        "outputId": "3d143a8d-53b6-41c3-d182-1a89da4837cf"
      },
      "source": [
        "score = model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 97.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7EmOkh4jSyu"
      },
      "source": [
        "# Predicting on custom image \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArR6RGc1hwIH",
        "outputId": "7ed0926e-9be3-4c99-8e98-66408c779f6d"
      },
      "source": [
        "import cv2 \n",
        " \n",
        "originalImage = cv2.imread('pizza.png')\n",
        "img = cv2.resize(originalImage, (224,224), interpolation=cv2.INTER_AREA)\n",
        "img = np.array([img])\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-wvM76wiNvY",
        "outputId": "2bfc8850-93d1-416f-afff-38099bc7a30c"
      },
      "source": [
        "feat = model_vgg.predict(img)\n",
        "\n",
        "pred = model.predict(feat)\n",
        "np.argmax(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}